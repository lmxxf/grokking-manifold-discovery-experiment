"""
ç¾¤ç»“æ„é‚»æ¥å…³ç³»åˆ†æ - æ¨¡åŠ æ³•
éªŒè¯"å‘ç°äº†ç»“æ„"è€Œé"åˆ†ç±»å˜ç´§"

æ ¸å¿ƒé—®é¢˜ï¼š
- 97 ä¸ªç°‡åœ¨ UMAP ç©ºé—´ä¸­çš„é‚»æ¥å…³ç³»æ˜¯å¦ç¬¦åˆç¾¤ç»“æ„ï¼Ÿ
- å³ï¼šlabel s çš„ç°‡æ˜¯å¦ä¸ label sÂ±1 çš„ç°‡ç©ºé—´ç›¸é‚»ï¼Ÿ

æ–¹æ³•ï¼š
1. åŠ è½½ Grokking åçš„ UMAP embedding
2. è®¡ç®—æ¯ä¸ªç°‡çš„ä¸­å¿ƒ
3. æ„å»ºé‚»æ¥çŸ©é˜µï¼ˆåŸºäºç°‡ä¸­å¿ƒè·ç¦»ï¼‰
4. æ£€æŸ¥é‚»æ¥å…³ç³»æ˜¯å¦ç¬¦åˆå¾ªç¯ç¾¤ç»“æ„ Z_97

ç”¨æ³•ï¼ˆåœ¨ Docker å®¹å™¨å†…ï¼‰ï¼š
    python /workspace/ai-theorys-study/arxiv/wechat67/exp_group1_addition/code/analyze_adjacency.py
"""

import numpy as np
import matplotlib.pyplot as plt
from umap import UMAP
from scipy.spatial.distance import cdist
import os
import json

# ============ é…ç½® ============
RESULTS_DIR = "/workspace/ai-theorys-study/arxiv/wechat67/exp_group1_addition/results"
ACTIVATIONS_DIR = os.path.join(RESULTS_DIR, "activations")
OUTPUT_DIR = os.path.join(RESULTS_DIR, "adjacency_analysis")

# Grokking åçš„æ—¶é—´ç‚¹
STEP = 100000

P = 97  # æ¨¡æ•°


def load_activations(step):
    """åŠ è½½æŒ‡å®š step çš„æ¿€æ´»"""
    path = os.path.join(ACTIVATIONS_DIR, f"step_{step:06d}.npz")
    if not os.path.exists(path):
        # å°è¯•æ‰¾æœ€è¿‘çš„
        import glob
        files = sorted(glob.glob(os.path.join(ACTIVATIONS_DIR, "step_*.npz")))
        if not files:
            raise FileNotFoundError(f"No activation files found in {ACTIVATIONS_DIR}")
        path = files[-1]  # ç”¨æœ€åä¸€ä¸ª
        print(f"Using {path} instead of step {step}")
    data = np.load(path)
    return data["hidden"], data["labels"]


def compute_cluster_centers(embedding, labels, p):
    """è®¡ç®—æ¯ä¸ª label å¯¹åº”ç°‡çš„ä¸­å¿ƒ"""
    centers = {}
    for label in range(p):
        mask = labels == label
        if mask.sum() > 0:
            centers[label] = embedding[mask].mean(axis=0)
    return centers


def compute_adjacency_score(centers, p):
    """
    è®¡ç®—é‚»æ¥å…³ç³»å¾—åˆ†

    å¯¹äºå¾ªç¯ç¾¤ Z_pï¼Œlabel s åº”è¯¥ä¸ s-1 å’Œ s+1 ç›¸é‚»
    å¾—åˆ† = å®é™…æœ€è¿‘é‚»ä¸­æœ‰å¤šå°‘æ˜¯"æ­£ç¡®çš„"ï¼ˆå³ sÂ±1ï¼‰
    """
    # æ„å»ºä¸­å¿ƒçŸ©é˜µ
    center_labels = sorted(centers.keys())
    center_matrix = np.array([centers[l] for l in center_labels])

    # è®¡ç®—è·ç¦»çŸ©é˜µ
    dist_matrix = cdist(center_matrix, center_matrix, metric='euclidean')

    # å¯¹æ¯ä¸ªç°‡ï¼Œæ‰¾æœ€è¿‘çš„ 2 ä¸ªé‚»å±…ï¼ˆæ’é™¤è‡ªå·±ï¼‰
    correct_neighbors = 0
    total_neighbors = 0

    neighbor_details = []

    for i, label in enumerate(center_labels):
        # è·å–åˆ°å…¶ä»–ç°‡çš„è·ç¦»
        distances = dist_matrix[i].copy()
        distances[i] = np.inf  # æ’é™¤è‡ªå·±

        # æ‰¾æœ€è¿‘çš„ 2 ä¸ª
        nearest_indices = np.argsort(distances)[:2]
        nearest_labels = [center_labels[idx] for idx in nearest_indices]

        # æ£€æŸ¥æ˜¯å¦æ˜¯ sÂ±1ï¼ˆmod pï¼‰
        expected_neighbors = [(label - 1) % p, (label + 1) % p]

        for neighbor in nearest_labels:
            total_neighbors += 1
            if neighbor in expected_neighbors:
                correct_neighbors += 1

        neighbor_details.append({
            "label": int(label),
            "nearest_neighbors": [int(n) for n in nearest_labels],
            "expected_neighbors": expected_neighbors,
            "correct": sum(1 for n in nearest_labels if n in expected_neighbors),
        })

    score = correct_neighbors / total_neighbors if total_neighbors > 0 else 0

    return score, neighbor_details, dist_matrix, center_labels


def visualize_adjacency(embedding, labels, centers, neighbor_details, output_path):
    """å¯è§†åŒ–é‚»æ¥å…³ç³»"""
    fig, axes = plt.subplots(1, 2, figsize=(16, 8))

    # å·¦å›¾ï¼šUMAP embeddingï¼Œç”¨ç®­å¤´è¿æ¥ç›¸é‚»ç°‡
    ax1 = axes[0]
    scatter = ax1.scatter(
        embedding[:, 0], embedding[:, 1],
        c=labels, cmap='hsv', s=3, alpha=0.5
    )

    # ç”»å‡ºæ¯ä¸ªç°‡åˆ°å…¶æœ€è¿‘é‚»çš„è¿çº¿
    for detail in neighbor_details:
        label = detail["label"]
        if label not in centers:
            continue
        center = centers[label]
        for neighbor in detail["nearest_neighbors"]:
            if neighbor in centers:
                neighbor_center = centers[neighbor]
                # é¢œè‰²ï¼šæ­£ç¡®é‚»æ¥=ç»¿è‰²ï¼Œé”™è¯¯=çº¢è‰²
                expected = detail["expected_neighbors"]
                color = 'green' if neighbor in expected else 'red'
                ax1.plot(
                    [center[0], neighbor_center[0]],
                    [center[1], neighbor_center[1]],
                    color=color, alpha=0.3, linewidth=0.5
                )

    ax1.set_title(f"Adjacency Relations (green=correct, red=incorrect)")
    ax1.set_xlabel("UMAP 1")
    ax1.set_ylabel("UMAP 2")

    # å³å›¾ï¼šæ­£ç¡®é‚»æ¥æ¯”ä¾‹çš„åˆ†å¸ƒ
    ax2 = axes[1]
    correct_counts = [d["correct"] for d in neighbor_details]
    ax2.hist(correct_counts, bins=[0, 1, 2, 3], align='left', rwidth=0.8, edgecolor='black')
    ax2.set_xticks([0, 1, 2])
    ax2.set_xticklabels(['0/2 correct', '1/2 correct', '2/2 correct'])
    ax2.set_xlabel("Correct neighbors (out of 2)")
    ax2.set_ylabel("Number of clusters")
    ax2.set_title(f"Distribution of Correct Adjacencies")

    # ç»Ÿè®¡
    total_correct = sum(correct_counts)
    total_possible = len(correct_counts) * 2
    score = total_correct / total_possible
    ax2.text(0.5, 0.9, f"Overall score: {score:.1%}",
             transform=ax2.transAxes, fontsize=14, ha='center')

    plt.tight_layout()
    plt.savefig(output_path, dpi=150, bbox_inches='tight')
    plt.close()
    print(f"Saved visualization to {output_path}")


def main():
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    print("Loading activations...")
    hidden, labels = load_activations(STEP)
    print(f"Loaded {len(labels)} samples")

    print("Running UMAP...")
    reducer = UMAP(n_neighbors=15, min_dist=0.1, metric='cosine', random_state=42)
    embedding = reducer.fit_transform(hidden)

    print("Computing cluster centers...")
    centers = compute_cluster_centers(embedding, labels, P)
    print(f"Found {len(centers)} clusters (expected {P})")

    print("Analyzing adjacency relations...")
    score, neighbor_details, dist_matrix, center_labels = compute_adjacency_score(centers, P)

    print(f"\n{'='*50}")
    print(f"ADJACENCY ANALYSIS RESULTS (Addition mod {P})")
    print(f"{'='*50}")
    print(f"Overall adjacency score: {score:.1%}")
    print(f"(100% = all nearest neighbors are sÂ±1)")
    print(f"(Random baseline â‰ˆ 2/{P} â‰ˆ {2/P:.1%})")

    # è¯¦ç»†ç»Ÿè®¡
    correct_counts = [d["correct"] for d in neighbor_details]
    print(f"\nDistribution:")
    print(f"  2/2 correct: {correct_counts.count(2)} clusters ({correct_counts.count(2)/len(correct_counts):.1%})")
    print(f"  1/2 correct: {correct_counts.count(1)} clusters ({correct_counts.count(1)/len(correct_counts):.1%})")
    print(f"  0/2 correct: {correct_counts.count(0)} clusters ({correct_counts.count(0)/len(correct_counts):.1%})")

    # å¯è§†åŒ–
    print("\nGenerating visualization...")
    visualize_adjacency(
        embedding, labels, centers, neighbor_details,
        os.path.join(OUTPUT_DIR, "adjacency_visualization.png")
    )

    # ä¿å­˜ç»“æœ
    results = {
        "step": STEP,
        "p": P,
        "operation": "addition",
        "num_clusters": len(centers),
        "adjacency_score": score,
        "random_baseline": 2 / P,
        "distribution": {
            "2_correct": correct_counts.count(2),
            "1_correct": correct_counts.count(1),
            "0_correct": correct_counts.count(0),
        },
        "neighbor_details": neighbor_details,
    }

    with open(os.path.join(OUTPUT_DIR, "adjacency_results.json"), "w") as f:
        json.dump(results, f, indent=2)

    print(f"\nResults saved to {OUTPUT_DIR}")

    # ç»“è®º
    print(f"\n{'='*50}")
    print("CONCLUSION:")
    if score > 0.5:
        print(f"âœ… Strong evidence for group structure discovery")
        print(f"   Adjacency score ({score:.1%}) >> random baseline ({2/P:.1%})")
    elif score > 0.2:
        print(f"ğŸ¤” Moderate evidence for group structure")
        print(f"   Adjacency score ({score:.1%}) > random baseline ({2/P:.1%})")
    else:
        print(f"âŒ Weak evidence for group structure")
        print(f"   Adjacency score ({score:.1%}) â‰ˆ random baseline ({2/P:.1%})")
    print(f"{'='*50}")


if __name__ == "__main__":
    main()
